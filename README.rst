|test| |codecov| |docs|

.. |test| image:: https://github.com/intsystems/ProjectTemplate/workflows/test/badge.svg
    :target: https://github.com/intsystems/ProjectTemplate/tree/master
    :alt: Test status
    
.. |codecov| image:: https://img.shields.io/codecov/c/github/intsystems/ProjectTemplate/master
    :target: https://app.codecov.io/gh/intsystems/ProjectTemplate
    :alt: Test coverage
    
.. |docs| image:: https://github.com/intsystems/ProjectTemplate/workflows/docs/badge.svg
    :target: https://intsystems.github.io/ProjectTemplate/
    :alt: Docs status


.. class:: center

    :Название исследуемой задачи: Меры близости в задачах self-supervised learning
    :Тип научной работы: M1P
    :Автор: Виданов Андрей Николаевич
    :Научный руководитель: Полина Барабанщикова

Abstract
========

С каждым днем в мире появляется все больше и больше данных, которых мы можем использовать для целей машинного обучения. Однако для классических методом обучения с учителем нужна разметка на данных, которая требует затрат человеко-часов и, соответственно, денег. Вот почему в последние годы все активнее развиваются техники обучения без учителя, которые не требуют предварительной разметки на данных. Для изображений является полезной задача создания эмбеддингов, поскольку они могут использоваться в различных задачах машинного обучения для повышения качества финальных моделей. Переход к подобным методам бесспорно является перспективным, но все же таит в себе много подводных камней с которыми придется столкнуться современной науке. В частности, для задач связанными с изображениями нет методов для создания отрицательных пар, обучаясь на которых модель могла бы улавливать чем отличаются кардинально разные картинки. Избежать данной проблемы можно спроектировав модели, не требующие негативных пар. Модель минимизирует расстояние между эмбеддингами похожих картинок. Но данные методы склонны к вырождению, иначе говоря сталкиваются с коллапсом(явление, когда модель сопоставляет всем картинкам одно и то же представление). В результате чего стоит крайне аккуратно подбирать лосс-функции или проектировать модель. Именно освещению данной темы посвящена эта статья. 


